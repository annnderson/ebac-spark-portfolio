{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  Exercício 1 - Tratamento de Dados com PySpark"
      ],
      "metadata": {
        "id": "vXkLYOCZqjHQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objetivo"
      ],
      "metadata": {
        "id": "5nTdayGfseEe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demonstrar técnicas de limpeza e preparação de dados usando PySpark"
      ],
      "metadata": {
        "id": "1wJiWfZmshHP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "1CuI52f3uIRu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- videos-stats.csv: Estatísticas de vídeos\n",
        "- comments.csv: Comentários dos vídeos\n",
        "- USvideos.csv: Vídeos dos EUA (para join)"
      ],
      "metadata": {
        "id": "H4qqJfVluRNv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Técnicas aplicadas:"
      ],
      "metadata": {
        "id": "OU2hvCi1uf8Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Tratamento de valores nulos\n",
        "2. Conversão de tipos de dados\n",
        "3. Remoção de duplicatas\n",
        "4. Criação de novas colunas\n",
        "5. Junção de DataFrames\n",
        "6. Exportação para formato Parquet"
      ],
      "metadata": {
        "id": "cpsiTmQBuo3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalação do PySpark\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "m-ENajbTvQHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação de Bibliotecas\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, count, when, regexp_extract, sum as spark_sum, to_date, date_format"
      ],
      "metadata": {
        "id": "woolwPX1vSnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicialização da Sessão Spark\n",
        "spark = SparkSession.builder.appName(\"EBAC_Data_Cleaning\").getOrCreate()"
      ],
      "metadata": {
        "id": "-AMp0rRIvVtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Leitura do Arquivo videos-stats.csv\n",
        "df_video = spark.read \\\n",
        "    .option('header', 'true') \\\n",
        "    .option(\"inferSchema\", \"true\") \\\n",
        "    .csv('/content/drive/MyDrive/Material de apoio - M27 (1)/videos-stats.csv')"
      ],
      "metadata": {
        "id": "RSj4QfVWvfRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Schema do DataFrame de vídeos:\")\n",
        "df_video.printSchema()\n",
        "\n",
        "print(\"\\nPrimeiras 10 linhas:\")\n",
        "df_video.show(10)"
      ],
      "metadata": {
        "id": "MVfoUsBiwA9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Análise inicial dos dados\n",
        "print(\"Quantidade de registros em df_video:\", df_video.count())\n",
        "print(\"Colunas disponíveis:\", df_video.columns)"
      ],
      "metadata": {
        "id": "EwizVLFkwMTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tratamento de Valores Nulos - Substituição por 0\n",
        "print(\"Valores nulos antes do tratamento:\")\n",
        "null_counts_before = df_video.agg(*[\n",
        "    spark_sum(col(c).isNull().cast(\"int\")).alias(c)\n",
        "    for c in ['Likes', 'Comments', 'Views']\n",
        "])\n",
        "\n",
        "null_counts_before.show()"
      ],
      "metadata": {
        "id": "Vwf1RotYwnu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Substitui valores nulos nas colunas numéricas por 0\n",
        "df_video = df_video.na.fill({\n",
        "    'Likes': 0,\n",
        "    'Comments': 0,\n",
        "    'Views': 0\n",
        "})\n",
        "\n",
        "print(\"Valores nulos após o tratamento:\")\n",
        "null_counts_after = df_video.agg(*[\n",
        "    spark_sum(col(c).isNull().cast(\"int\")).alias(c)\n",
        "    for c in ['Likes', 'Comments', 'Views']\n",
        "])\n",
        "\n",
        "null_counts_after.show()"
      ],
      "metadata": {
        "id": "6ARiokt1wzYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Leitura do Arquivo comments.csv\n",
        "df_comentario = spark.read \\\n",
        "    .option('header', 'true') \\\n",
        "    .option(\"inferSchema\", \"true\") \\\n",
        "    .csv('/content/drive/MyDrive/Material de apoio - M27 (1)/comments.csv')\n",
        "\n",
        "print(\"Schema do DataFrame de comentários:\")\n",
        "df_comentario.printSchema()\n",
        "\n",
        "print(\"\\nPrimeiras 10 linhas de comentários:\")\n",
        "df_comentario.show(10)"
      ],
      "metadata": {
        "id": "rYAL9U77xSEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Análise dos dados de comentários\n",
        "print(\"Quantidade de registros em df_comentario:\", df_comentario.count())"
      ],
      "metadata": {
        "id": "_gGSO4_PxYnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove linhas com Video ID nulo\n",
        "df_video_sem_nulos = df_video.dropna(subset=[\"Video ID\"])\n",
        "df_comentario_sem_nulos = df_comentario.dropna(subset=[\"Video ID\"])\n",
        "\n",
        "print(\"Quantidade após remoção de nulos em Video ID:\")\n",
        "print(f\"Vídeos: {df_video_sem_nulos.count()}\")\n",
        "print(f\"Comentários: {df_comentario_sem_nulos.count()}\")"
      ],
      "metadata": {
        "id": "qAq3TmOKxqxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicatas baseadas no Video ID\n",
        "df_video = df_video.dropDuplicates(subset=['Video ID'])\n",
        "print(\"Quantidade após remoção de duplicatas:\", df_video.count())"
      ],
      "metadata": {
        "id": "pHiOb9GTxu7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conversão de tipos de dados\n",
        "df_video = df_video.withColumn(\"Likes\", col(\"Likes\").cast(\"int\")) \\\n",
        "                   .withColumn(\"Comments\", col(\"Comments\").cast(\"int\")) \\\n",
        "                   .withColumn(\"Views\", col(\"Views\").cast(\"int\"))\n",
        "\n",
        "df_comentario = df_comentario.withColumn(\"Likes\", col(\"Likes\").cast(\"int\")) \\\n",
        "                             .withColumn(\"Sentiment\", col(\"Sentiment\").cast(\"int\")) \\\n",
        "                             .withColumnRenamed('Likes', 'Likes_Comment')\n",
        "\n",
        "print(\"Schema após conversão de tipos:\")\n",
        "df_video.printSchema()"
      ],
      "metadata": {
        "id": "FP3W2OiXx4FZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criação de nova coluna: Interaction (soma de Likes, Comments e Views)\n",
        "df_video = df_video.withColumn('Interaction', col('Likes') + col('Comments') + col('Views'))\n",
        "df_video.select('Video ID', 'Title', 'Likes', 'Comments', 'Views', 'Interaction').show(10)"
      ],
      "metadata": {
        "id": "mFgxWBqEyU13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformação de datas\n",
        "df_video = df_video.withColumn(\"Published_At\", to_date(col(\"Published At\"))) \\\n",
        "                   .withColumn('Year', date_format(col('Published_At'), 'yyyy'))\n",
        "\n",
        "print(\"Datas transformadas:\")\n",
        "df_video.select('Published At', 'Published_At', 'Year').show(10)"
      ],
      "metadata": {
        "id": "oqn-KbbuyXM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# JOIN entre vídeos e comentários\n",
        "df_join_video_comments = df_video.join(df_comentario, \"Video ID\", \"inner\")\n",
        "print(f\"Quantidade de registros após JOIN: {df_join_video_comments.count()}\")\n",
        "df_join_video_comments.show(10)"
      ],
      "metadata": {
        "id": "Nln9v6xDyaS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Leitura e JOIN com dados dos EUA\n",
        "df_us_videos = spark.read \\\n",
        "    .option('header', 'true') \\\n",
        "    .option(\"inferSchema\", \"true\") \\\n",
        "    .csv('/content/drive/MyDrive/Material de apoio - M27 (1)/USvideos.csv')\n",
        "\n",
        "df_join_video_usvideos = df_video.join(df_us_videos, \"Title\", \"inner\")\n",
        "print(f\"Quantidade de registros após JOIN com US videos: {df_join_video_usvideos.count()}\")\n",
        "df_join_video_usvideos.show(10)"
      ],
      "metadata": {
        "id": "aHrv5PuG1N5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remoção de colunas desnecessárias\n",
        "colunas_para_remover = ['_c0']\n",
        "for coluna in colunas_para_remover:\n",
        "    if coluna in df_video.columns:\n",
        "        df_video = df_video.drop(coluna)\n",
        "        print(f\"Coluna '{coluna}' removida do DataFrame de vídeos\")\n",
        "\n",
        "    if coluna in df_join_video_comments.columns:\n",
        "        df_join_video_comments = df_join_video_comments.drop(coluna)\n",
        "        print(f\"Coluna '{coluna}' removida do DataFrame de join\")"
      ],
      "metadata": {
        "id": "hZNYniNo1Ve1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exportação para Parquet (formato otimizado)\n",
        "df_video.write.mode('overwrite').option('header', 'true') \\\n",
        "          .parquet('/content/drive/MyDrive/Projeto Pyspark/videos-tratados-parquet')\n",
        "\n",
        "df_join_video_comments.write.mode('overwrite').option('header', 'true') \\\n",
        "          .parquet('/content/drive/MyDrive/Projeto Pyspark/videos-comments-tratados-parquet')\n",
        "\n",
        "print(\"Dados exportados para Parquet com sucesso!\")"
      ],
      "metadata": {
        "id": "R0ALbJCW1crX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificação dos dados salvos\n",
        "print(\"Dados de vídeos salvos:\")\n",
        "spark.read.option('header', 'true') \\\n",
        "    .parquet('/content/drive/MyDrive/Projeto Pyspark/videos-tratados-parquet') \\\n",
        "    .show(5)\n",
        "\n",
        "print(\"Dados de vídeos e comentários salvos:\")\n",
        "spark.read.option('header', 'true') \\\n",
        "    .parquet('/content/drive/MyDrive/Projeto Pyspark/videos-comments-tratados-parquet') \\\n",
        "    .show(5)"
      ],
      "metadata": {
        "id": "Ugj6bUFF1iEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encerramento da Sessão Spark\n",
        "spark.stop()\n",
        "print(\"Sessão Spark encerrada.\")"
      ],
      "metadata": {
        "id": "oMaStu-P1ls2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}